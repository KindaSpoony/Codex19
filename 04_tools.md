# Investigative Tools & Modules Reference

## OSINT Tools and Resources

We deploy a range of Open-Source Intelligence (OSINT) tools to gather information, with each tool used in a controlled, ethical manner. All data collection adheres to legal and ethical standards (no unauthorized access or hacking), and results are filtered for credibility per our source evaluation guidelines. Key tool categories include:

- **Web Search Engines (e.g., Google, Bing)**: Provide broad access to indexed web content for initial fact-finding or lead generation. *Query Strategy*: use precise keywords and advanced operators (quoting exact phrases, using `site:` for domain-specific searches, `-` to exclude terms) to pinpoint relevant information. *Credibility Integration*: search results are sifted through credibility filters—prioritizing reputable domains (official, academic, or well-established sources) and flagging low-quality sites. The LLM cross-verifies critical facts across multiple search hits, in line with source-evaluation rules, to ensure only reliable information is used.
- **News & Media Archives**: Tools such as Google News, Factiva, and LexisNexis index newspapers, journals, and media reports. They retrieve historical and current news articles or press releases relevant to the investigation. *Query Strategy*: use date-range filters and specific media sources or keywords to find context, quotes, or background in credible news outlets. *Credibility Integration*: results are filtered by source reputation (favoring mainstream, vetted media). The system applies credibility checks (as defined in `03_source-evaluation.md`) to identify potential bias or misinformation, ensuring cited media reports meet our reliability standards.
- **Academic Databases**: Scholarly search engines like Google Scholar and academic journal databases help find peer-reviewed papers, studies, or expert analyses. *Query Strategy*: search by keywords, author names, or publication titles; use filters such as filetype (PDF for papers) or `site:.edu` for university repositories. *Credibility Integration*: although academic sources are inherently high-credibility, the LLM still evaluates the publication venue and author credentials. It cross-references findings with other literature, flagging any outlier claims and citing academic sources with proper context to preserve transparency.
- **Public Records & Databases**: Government databases, public record portals, and official registries (e.g., court records, company registries, SEC EDGAR) provide official data that can corroborate investigative leads. *Query Strategy*: use targeted queries on government or institutional sites (often combining `site:.gov` or specific database search interfaces) and keywords like names, case numbers, or document types. *Credibility Integration*: information from official records is treated as authoritative but is still checked for context and completeness. The LLM's credibility filter gives high weight to these sources while ensuring the data is up to date and matches other known records.
- **Social Media Search**: Platform-specific search features and third-party OSINT tools for social content (e.g., Twitter Advanced Search, LinkedIn search, Reddit queries) collect posts, profiles, or social interactions that might provide leads or corroborating evidence. *Query Strategy*: use advanced search parameters (hashtags, mentions, date filters, or `inurl:` with profile/user IDs) to locate relevant social media posts or user data. *Credibility Integration*: because social content can be volatile and unverified, the system verifies account authenticity, cross-checks claims in posts against news or official sources, and notes emotional tone or potential bias (per `02_heuristics.md`). Any social media-derived information is triangulated with other sources before being taken as fact.
- **Web Caches & Archives**: Cached page retrieval and web archives (e.g., Google Cache, Internet Archive’s Wayback Machine) provide historical snapshots of content that might have been changed or removed. *Query Strategy*: use the `cache:` operator for recent Google-cached pages or search Archive.org by URL and date. *Credibility Integration*: cached content inherits the credibility of the original site, but the module confirms the snapshot’s timestamp and checks if the content was altered since. The LLM annotates findings with the retrieval date and uses multiple archive sources, ensuring page integrity is trustworthy and auditable.

## LLM Operational Modules

To conduct investigations systematically, the AI operates through specialized internal modules. Each module governs a facet of behavior or analysis, ensuring the workflow remains ethical, logical, and aligned with project standards (as detailed in `ethics.md`, `02_heuristics.md`, and `03_source-evaluation.md`). Key operational modules include:

- **Ethical/Policy Filter**: Monitors all queries, data retrievals, and outputs against the project’s ethical guidelines and policies. It filters or redacts content that violates privacy, legal restrictions, or ethical standards, ensuring compliance and preventing disallowed activities.
- **Logic Gates**: Implements conditional checkpoints in the AI’s reasoning process. At critical junctures, predefined logic rules (from `02_heuristics.md`) evaluate whether the next step is warranted. These gates maintain logical consistency and prevent premature conclusions.
- **Source Evaluation Routines**: Automatically assess each information source’s credibility and relevance using criteria set in `03_source-evaluation.md`. By scoring sources, the AI leans on high-quality evidence and logs credibility metadata for transparent reporting.
- **Triangulation Module**: Cross-verifies key facts and claims across multiple independent sources. Contradictory evidence triggers further analysis or flags uncertainties for review, increasing overall reliability.
- **Threat Pattern Detection**: Scans collected data for known patterns or indicators of threats relevant to the investigation, such as fraud or cyber-attacks. Early detection helps prioritize leads that might involve security issues.
- **Emotional Tone Gates**: Monitors the emotional and subjective tone of both source content and the AI’s generated text, prompting rephrasing or additional context if the tone becomes biased or overly emotive.
- **Confidence Intervaling**: Evaluates the certainty level of findings, requiring an internal confidence score for each conclusion. This provides transparency about how much trust to place in a result.
- **Historical Consistency Check**: Verifies that information and assertions remain consistent over time and with known historical facts, forcing reconciliation when discrepancies arise.

## Google Dorking Toolkit

When standard search techniques aren’t enough, we employ advanced Google search operators (often called “Google Dorking”) to uncover hard-to-find information. These operators allow targeted queries that can retrieve specific file types, find information within URLs or titles, access cached pages, and more. Key operators include:

| Operator & Category | Syntax Usage | Investigative Purpose | Example Query |
|---------------------|-------------|----------------------|---------------|
| File Type Search | `filetype:<ext> <keywords>` | Find specific document types (PDFs, DOCX, XLS, etc.) containing relevant keywords. Useful for locating reports, presentations, or data dumps not easily found via normal web browsing. | `filetype:pdf site:example.gov "annual budget 2023"` |
| In-URL Keyword | `inurl:<term>` | Discover pages with certain terms in the URL, often used to find portals or user profiles. | `inurl:report site:example.com "Q4 2024"` |
| In-Title Keyword | `intitle:<term>` | Locate pages with specific words in the HTML title, such as a page titled "Investigation Report." | `intitle:"Employee Directory" company name` |
| Cache Retrieval | `cache:<URL>` | Retrieve Google’s cached snapshot of a page to view content that might have changed or been removed. | `cache:example.com "policy update"` |
| Site + Filetype Combo | `site:<domain> filetype:<ext> <keywords>` | Combine site restriction with file type to target specific repositories of information. | `site:.gov filetype:xls "cybersecurity budget"` |

Each of these Google dorking techniques must be used judiciously. They can reveal valuable data, but we ensure the queries remain within ethical boundaries—focusing only on publicly available information. The LLM uses these operators in tandem with the above credibility filters and modules, cross-checking and documenting all findings to maintain an audit trail consistent with our investigative standards.
